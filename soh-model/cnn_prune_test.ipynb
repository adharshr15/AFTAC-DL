{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4897c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4897c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 24 * 2\n",
    "STEP_SIZE = 24\n",
    "FORECAST_HORIZON = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "SELECT_MODEL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de0241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed feature data\n",
    "X_train_feature = np.load(f\"./data/finalized/X_train_feature_{SELECT_MODEL}.npy\")\n",
    "Y_train_feature = np.load(f\"./data/finalized/Y_train_feature_{SELECT_MODEL}.npy\")\n",
    "X_val_feature = np.load(f\"./data/finalized/X_val_feature_{SELECT_MODEL}.npy\")\n",
    "Y_val_feature = np.load(f\"./data/finalized/Y_val_feature_{SELECT_MODEL}.npy\")\n",
    "X_test_feature = np.load(f\"./data/finalized/X_test_feature_{SELECT_MODEL}.npy\")\n",
    "Y_test_feature = np.load(f\"./data/finalized/Y_test_feature_{SELECT_MODEL}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48547cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9bd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(seq_length, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Simple 1D CNN for time-series regression built with TensorFlow/Keras.\n",
    "    Architecture: Conv1D -> MaxPool -> Dense -> Output\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(seq_length, 1)),\n",
    "        layers.Conv1D(filters=64, kernel_size=5, activation='relu', padding='valid'),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(50, activation='relu'),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Dense(forecast_horizon)\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    \"\"\"Run predictions\"\"\"\n",
    "    y_pred = model.predict(X_test, verbose=0)\n",
    "    y_true = Y_test\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "def print_metrics(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"Print regression metrics including variance analysis\"\"\"\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
    "    mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
    "    \n",
    "    # Variance metrics\n",
    "    true_std = np.std(y_true.flatten())\n",
    "    pred_std = np.std(y_pred.flatten())\n",
    "    variance_ratio = pred_std / true_std if true_std > 0 else 0\n",
    "    \n",
    "    # Range metrics\n",
    "    true_range = np.max(y_true.flatten()) - np.min(y_true.flatten())\n",
    "    pred_range = np.max(y_pred.flatten()) - np.min(y_pred.flatten())\n",
    "    range_ratio = pred_range / true_range if true_range > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{model_name} Regression Metrics:\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "    print(f\"\\nVariance Analysis:\")\n",
    "    print(f\"Actual Std Dev: {true_std:.4f}\")\n",
    "    print(f\"Predicted Std Dev: {pred_std:.4f}\")\n",
    "    print(f\"Variance Ratio (pred/actual): {variance_ratio:.4f}\")\n",
    "    print(f\"\\nRange Analysis:\")\n",
    "    print(f\"Actual Range: {true_range:.4f}\")\n",
    "    print(f\"Predicted Range: {pred_range:.4f}\")\n",
    "    print(f\"Range Ratio (pred/actual): {range_ratio:.4f}\")\n",
    "    \n",
    "    return y_true, y_pred, mse, mae, rmse, r2\n",
    "\n",
    "def evaluate_and_print_metrics(model, X_test, Y_test, model_name=\"Model\"):\n",
    "    y_true, y_pred = evaluate_model(model, X_test, Y_test)\n",
    "    return print_metrics(y_true, y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_with_variance_loss(alpha=0.15):\n",
    "    \"\"\"\n",
    "    Custom loss function that combines prediction accuracy with variance matching.\n",
    "    This helps prevent the model from dampening predictions (predicting too narrow a range).\n",
    "    \n",
    "    Args:\n",
    "        alpha: Weight for variance matching penalty (0.1-0.2 recommended)\n",
    "               Higher alpha = more emphasis on matching variance\n",
    "    \n",
    "    Returns:\n",
    "        Loss function compatible with Keras model.compile()\n",
    "    \"\"\"\n",
    "    @tf.keras.utils.register_keras_serializable(package='Custom', name=f'mse_variance_loss_alpha_{alpha}')\n",
    "    def loss(y_true, y_pred):\n",
    "        # Accuracy component: Standard MSE for prediction accuracy\n",
    "        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        \n",
    "        # Variance matching component: Penalize if predicted std differs from actual std\n",
    "        true_std = tf.math.reduce_std(y_true)\n",
    "        pred_std = tf.math.reduce_std(y_pred)\n",
    "        var_penalty = tf.square(true_std - pred_std)\n",
    "        \n",
    "        # Combined loss\n",
    "        return mse + alpha * var_penalty\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1815ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the TensorFlow/Keras CNN model\n",
    "model = create_cnn_model(X_train_feature.shape[1], FORECAST_HORIZON)\n",
    "\n",
    "# Compile the model with custom loss function to prevent dampening\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=mse_with_variance_loss(alpha=0.15),  # Custom loss to match variance\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(\"Using MSE + Variance Loss (alpha=0.15) to prevent prediction dampening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e360da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_feature,\n",
    "    Y_train_feature,\n",
    "    validation_data=(X_val_feature, Y_val_feature),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for overfitting\n",
    "final_train_loss = train_losses[-1]\n",
    "final_val_loss = val_losses[-1]\n",
    "loss_diff = final_val_loss - final_train_loss\n",
    "loss_ratio = final_val_loss / final_train_loss\n",
    "\n",
    "print(f\"\\nFinal Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}\")\n",
    "\n",
    "print(f\"Difference (Val - Train): {loss_diff:.4f}\")\n",
    "print(f\"Ratio (Val / Train): {loss_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_true, y_pred, mse, mae, rmse, r2 = evaluate_and_print_metrics(model, X_test_feature, Y_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scaler parameters\n",
    "MEAN = 40.00946858359476\n",
    "STD = 4.8101438894455\n",
    "\n",
    "# Unscale the predictions and actual values\n",
    "y_true_flat = np.array(y_true).reshape(-1)\n",
    "y_pred_flat = np.array(y_pred).reshape(-1)\n",
    "\n",
    "y_true_unscaled = (y_true_flat * STD) + MEAN\n",
    "y_pred_unscaled = (y_pred_flat * STD) + MEAN\n",
    "\n",
    "# Calculate unscaled MSE\n",
    "unscaled_mse = mean_squared_error(y_true_unscaled, y_pred_unscaled)\n",
    "unscaled_rmse = np.sqrt(unscaled_mse)\n",
    "unscaled_mae = mean_absolute_error(y_true_unscaled, y_pred_unscaled)\n",
    "\n",
    "print(f\"\\nUnscaled Metrics:\")\n",
    "print(f\"MSE: {unscaled_mse:.4f} °C²\")\n",
    "print(f\"RMSE: {unscaled_rmse:.4f} °C\")\n",
    "print(f\"MAE: {unscaled_mae:.4f} °C\")\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Sample a subset for visualization if too many points\n",
    "num_samples = min(10000, len(y_true_unscaled))\n",
    "if num_samples == 0:\n",
    "    print(\"No test samples available to plot.\")\n",
    "else:\n",
    "    # Use the first 200 samples instead of random samples\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(indices, y_true_unscaled[indices], 'b-', label='Actual', alpha=0.7)\n",
    "    plt.plot(indices, y_pred_unscaled[indices], 'r--', label='Predicted', alpha=0.7)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Temperature (°C)')\n",
    "    plt.title(f'Predictions vs Actual (Unscaled)\\n{SELECT_MODEL}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_true_unscaled, y_pred_unscaled, alpha=0.5)\n",
    "    mn = min(y_true_unscaled.min(), y_pred_unscaled.min())\n",
    "    mx = max(y_true_unscaled.max(), y_pred_unscaled.max())\n",
    "    plt.plot([mn, mx], [mn, mx], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Temperature (°C)')\n",
    "    plt.ylabel('Predicted Temperature (°C)')\n",
    "    plt.title('Prediction Scatter Plot')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nUnscaled value ranges:\")\n",
    "    print(f\"Actual: [{y_true_unscaled.min():.2f}°C, {y_true_unscaled.max():.2f}°C]\")\n",
    "    print(f\"Predicted: [{y_pred_unscaled.min():.2f}°C, {y_pred_unscaled.max():.2f}°C]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X values (input sequences) associated with the predictions\n",
    "X_associated = X_test_feature[indices]\n",
    "\n",
    "print(f\"Shape of associated input sequences: {X_associated.shape}\")\n",
    "print(f\"Number of samples: {len(X_associated)}\")\n",
    "print(f\"Sequence length: {X_associated.shape[1]}\")\n",
    "print(f\"\\nFirst associated input sequence (sample {indices[0]}):\")\n",
    "print(X_associated[0].flatten())\n",
    "print(f\"\\nCorresponding actual value: {y_true_unscaled[indices[0]]:.2f}°C\")\n",
    "print(f\"Corresponding predicted value: {y_pred_unscaled[indices[0]]:.2f}°C\")\n",
    "\n",
    "# Optionally visualize a few input sequences\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(min(6, len(X_associated))):\n",
    "    ax = axes[i]\n",
    "    sequence = X_associated[i].flatten()\n",
    "    \n",
    "    # Unscale the input sequence\n",
    "    sequence_unscaled = (sequence * STD) + MEAN\n",
    "    \n",
    "    ax.plot(sequence_unscaled, 'b-', linewidth=1.5)\n",
    "    ax.axhline(y=y_true_unscaled[indices[i]], color='g', linestyle='--', label=f'Actual: {y_true_unscaled[indices[i]]:.1f}°C')\n",
    "    ax.axhline(y=y_pred_unscaled[indices[i]], color='r', linestyle='--', label=f'Pred: {y_pred_unscaled[indices[i]]:.1f}°C')\n",
    "    ax.set_title(f'Sample {indices[i]} - Input Sequence')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Temperature (°C)')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNote: Each input sequence contains {SEQUENCE_LENGTH} time steps\")\n",
    "print(f\"The model uses these {SEQUENCE_LENGTH} historical values to predict the next value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c208d",
   "metadata": {},
   "source": [
    "# Pruning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c40674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, CalibrationDataReader, QuantType\n",
    "import onnx\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43738bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnitude_prune_model(model, target_sparsity=0.5):\n",
    "    \"\"\"\n",
    "    Manual magnitude-based pruning for TensorFlow/Keras models.\n",
    "    Sets the smallest magnitude weights to zero based on target sparsity.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model to prune\n",
    "        target_sparsity: Fraction of weights to prune (0.5 = 50%)\n",
    "    \n",
    "    Returns:\n",
    "        Pruned model with sparse weights\n",
    "    \"\"\"\n",
    "    # Create a new model with the same architecture but without cloning\n",
    "    # This avoids the serialization issue with custom loss functions\n",
    "    pruned_model = create_cnn_model(model.input_shape[1], model.output_shape[1])\n",
    "    pruned_model.set_weights(model.get_weights())\n",
    "    \n",
    "    total_params = 0\n",
    "    pruned_params = 0\n",
    "    \n",
    "    for layer in pruned_model.layers:\n",
    "        # Only prune layers with trainable weights (Conv, Dense)\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.get_weights()\n",
    "            \n",
    "            if len(weights) > 0:\n",
    "                # Get kernel weights\n",
    "                kernel = weights[0]\n",
    "                \n",
    "                # Flatten for easier threshold calculation\n",
    "                flat_kernel = kernel.flatten()\n",
    "                total_params += flat_kernel.size\n",
    "                \n",
    "                # Calculate magnitude threshold for this layer\n",
    "                threshold = np.percentile(np.abs(flat_kernel), target_sparsity * 100)\n",
    "                \n",
    "                # Create binary mask (1 = keep, 0 = prune)\n",
    "                mask = (np.abs(kernel) >= threshold).astype(np.float32)\n",
    "                \n",
    "                # Apply mask to weights\n",
    "                pruned_kernel = kernel * mask\n",
    "                pruned_params += np.sum(mask == 0)\n",
    "                \n",
    "                # Update layer weights\n",
    "                weights[0] = pruned_kernel\n",
    "                layer.set_weights(weights)\n",
    "                \n",
    "                # Print layer stats\n",
    "                layer_sparsity = (np.sum(mask == 0) / mask.size) * 100\n",
    "                print(f\"Layer '{layer.name}': {layer_sparsity:.1f}% sparse ({np.sum(mask == 0)}/{mask.size} zeros)\")\n",
    "    \n",
    "    overall_sparsity = (pruned_params / total_params) * 100\n",
    "    print(f\"\\nOverall Sparsity Achieved: {overall_sparsity:.2f}%\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Pruned (zero) parameters: {pruned_params:,}\")\n",
    "    print(f\"  Active parameters: {total_params - pruned_params:,}\")\n",
    "    \n",
    "    return pruned_model\n",
    "\n",
    "# Apply magnitude-based pruning to your trained model\n",
    "pruned_model = magnitude_prune_model(model, target_sparsity=0.5)\n",
    "\n",
    "# Compile the pruned model with the same custom loss\n",
    "pruned_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=mse_with_variance_loss(alpha=0.15),\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the pruned model to recover accuracy\n",
    "print(\"\\n=== Fine-tuning Pruned Model ===\")\n",
    "print(\"Training for 5 epochs to recover from pruning...\\n\")\n",
    "\n",
    "# Use lower learning rate for fine-tuning\n",
    "pruned_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Lower LR for fine-tuning\n",
    "    loss=mse_with_variance_loss(alpha=0.15),  # Keep the custom loss\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "callbacks_pruned = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# Fine-tune\n",
    "history_pruned = pruned_model.fit(\n",
    "    X_train_feature,\n",
    "    Y_train_feature,\n",
    "    validation_data=(X_val_feature, Y_val_feature),\n",
    "    epochs=5,  # Just a few epochs to recover\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks_pruned,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe820c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_sparsity(model):\n",
    "    \"\"\"Calculate actual sparsity of the model after pruning\"\"\"\n",
    "    total_weights = 0\n",
    "    zero_weights = 0\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            weights = layer.get_weights()[0]\n",
    "            total_weights += weights.size\n",
    "            zero_weights += np.sum(weights == 0)\n",
    "    \n",
    "    sparsity_pct = (zero_weights / total_weights) * 100\n",
    "    return sparsity_pct, total_weights, zero_weights\n",
    "\n",
    "# Evaluate the pruned model\n",
    "print(\"\\n=== Evaluating Pruned Model Performance ===\")\n",
    "y_true_pruned, y_pred_pruned, mse_pruned, mae_pruned, rmse_pruned, r2_pruned = evaluate_and_print_metrics(\n",
    "    pruned_model, X_test_feature, Y_test_feature, \"Pruned Model\"\n",
    ")\n",
    "\n",
    "# Verify sparsity\n",
    "sparsity, total, zeros = check_model_sparsity(pruned_model)\n",
    "print(f\"\\nVerified Sparsity: {sparsity:.2f}% ({zeros:,} / {total:,} weights are zero)\")\n",
    "final_pruned_model = pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab95f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pruned model temporarily for quantization\n",
    "# Note: Save weights only to avoid custom loss serialization issues\n",
    "_, temp_model_path = tempfile.mkstemp(suffix='.h5', dir='./model')\n",
    "\n",
    "# Save with custom objects to handle the custom loss function\n",
    "final_pruned_model.save(temp_model_path, save_format='h5', include_optimizer=False)\n",
    "print(f\"Pruned model saved temporarily at: {temp_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e4231",
   "metadata": {},
   "source": [
    "# Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensorflow Lite Quantization\n",
    "# Create a representative dataset generator for quantization\n",
    "def representative_dataset_gen():\n",
    "    \"\"\"\n",
    "    Generator function to provide representative samples for quantization.\n",
    "    Uses a subset of training data.\n",
    "    \"\"\"\n",
    "    num_calibration_samples = min(2000, len(X_train_feature))\n",
    "    for i in range(num_calibration_samples):\n",
    "        # Yield a single sample with correct shape for the model\n",
    "        yield [X_train_feature[i:i+1].astype(np.float32)]\n",
    "\n",
    "print(\"\\nRepresentative dataset generator created for quantization.\")\n",
    "\n",
    "# Convert the pruned model to TensorFlow Lite with 8-bit integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_pruned_model)\n",
    "\n",
    "# Set optimization flags for full integer quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "print(\"\\nTrying with dynamic range quantization instead...\")\n",
    "# Fallback to dynamic range quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_pruned_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "quantized_tflite_model = converter.convert()\n",
    "print(\"Dynamic range quantization successful!\")\n",
    "\n",
    "print(f\"\\n--- Saving Prune + Quantized Model ---\")\n",
    "\n",
    "# Save tensorflow lite model\n",
    "quantized_model_path = './model/pruned_quantized_model.tflite'\n",
    "with open(quantized_model_path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "print(f\"Location: {quantized_model_path}\")\n",
    "print(f\"Size: {len(quantized_tflite_model) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e080b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Onnx Model Quantization\n",
    "# Temporarily save the pruned model as ONNX\n",
    "temp_model_path = \"./model/pruned_model.onnx\"\n",
    "spec = (tf.TensorSpec(final_pruned_model.inputs[0].shape, tf.float32, name=\"input\"),)\n",
    "final_pruned_model.output_names = [\"output\"]\n",
    "model_proto, _ = tf2onnx.convert.from_keras(final_pruned_model, input_signature=spec, opset=13)\n",
    "\n",
    "with open (temp_model_path, \"wb\") as f:\n",
    "    f.write(model_proto.SerializeToString())\n",
    "\n",
    "# Turn the ONNX model into a quantized version using dynamic quantization\n",
    "print(\"\\n--- Quantizing ONNX Model ---\")\n",
    "quantized_onnx_path = \"./model/pruned_quantized_model.onnx\"\n",
    "quantize_dynamic(\n",
    "    model_input=temp_model_path,\n",
    "    model_output=quantized_onnx_path,\n",
    "    weight_type=QuantType.QUInt8  # or QInt8\n",
    ")\n",
    "\n",
    "print(f\"\\nDynamic quantization complete!\")\n",
    "print(f\"Location: {quantized_onnx_path}\")\n",
    "print(f\"Size: {os.path.getsize(quantized_onnx_path) / 1024:.2f} KB\")\n",
    "\n",
    "# Compare sizes\n",
    "original_onnx_size = os.path.getsize(temp_model_path)\n",
    "quantized_onnx_size = os.path.getsize(quantized_onnx_path)\n",
    "compression_ratio = original_onnx_size / quantized_onnx_size\n",
    "\n",
    "print(f\"\\nONNX Model Compression:\")\n",
    "print(f\"  Original: {original_onnx_size / 1024:.2f} KB\")\n",
    "print(f\"  Quantized: {quantized_onnx_size / 1024:.2f} KB\")\n",
    "print(f\"  Compression: {compression_ratio:.2f}x smaller ({(1 - quantized_onnx_size/original_onnx_size)*100:.1f}% reduction)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894958e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the quantized TFLite model\n",
    "print(\"\\n--- Evaluating Quantized Model ---\")\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=quantized_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(f\"Input details: {input_details[0]['shape']}, dtype: {input_details[0]['dtype']}\")\n",
    "print(f\"Output details: {output_details[0]['shape']}, dtype: {output_details[0]['dtype']}\")\n",
    "\n",
    "# Make predictions on test set\n",
    "quantized_predictions = []\n",
    "\n",
    "for i in range(len(X_test_feature)):\n",
    "    # Prepare input\n",
    "    input_data = X_test_feature[i:i+1].astype(input_details[0]['dtype'])\n",
    "    \n",
    "    # If input is int8, we need to quantize\n",
    "    if input_details[0]['dtype'] == np.int8:\n",
    "        input_scale, input_zero_point = input_details[0]['quantization']\n",
    "        input_data = (input_data / input_scale + input_zero_point).astype(np.int8)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get output\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    # If output is int8, we need to dequantize\n",
    "    if output_details[0]['dtype'] == np.int8:\n",
    "        output_scale, output_zero_point = output_details[0]['quantization']\n",
    "        output_data = (output_data.astype(np.float32) - output_zero_point) * output_scale\n",
    "    \n",
    "    quantized_predictions.append(output_data[0])\n",
    "\n",
    "quantized_predictions = np.array(quantized_predictions)\n",
    "\n",
    "# Calculate metrics\n",
    "y_true_flat_quant = Y_test_feature.flatten()\n",
    "y_pred_flat_quant = quantized_predictions.flatten()\n",
    "\n",
    "y_true, y_pred, mse_quantized, mae_quantized, rmse_quantized, r2_quantized = print_metrics(y_true_flat_quant, y_pred_flat_quant, \"Quantized Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model sizes\n",
    "import os\n",
    "\n",
    "# Get original model size\n",
    "_, original_model_path = tempfile.mkstemp(suffix='.h5', dir=\"./model\")\n",
    "print(original_model_path)\n",
    "\n",
    "# Save without optimizer to avoid custom loss serialization issues\n",
    "model.save(original_model_path, save_format='h5', include_optimizer=False)\n",
    "original_size = os.path.getsize(original_model_path)\n",
    "\n",
    "# Get pruned model size (already saved earlier)\n",
    "pruned_size = os.path.getsize(temp_model_path)\n",
    "\n",
    "# Get quantized model size\n",
    "quantized_size = len(quantized_tflite_model)\n",
    "\n",
    "print(\"\\n=== Model Size Comparison ===\")\n",
    "print(f\"Original Model: {original_size / 1024:.2f} KB\")\n",
    "print(f\"Pruned Model: {pruned_size / 1024:.2f} KB ({(1 - pruned_size/original_size)*100:.1f}% reduction)\")\n",
    "print(f\"Pruned + Quantized Model: {quantized_size / 1024:.2f} KB ({(1 - quantized_size/original_size)*100:.1f}% reduction)\")\n",
    "print(f\"\\nTotal compression: {original_size / quantized_size:.2f}x smaller\")\n",
    "\n",
    "print(\"\\n=== Final Model Comparison ===\")\n",
    "print(f\"{'Model':<25} {'MSE':<10} {'MAE':<10} {'R²':<10}\")\n",
    "print(f\"{'-'*55}\")\n",
    "print(f\"{'Original':<25} {mse:<10.4f} {mae:<10.4f} {r2:<10.4f}\")\n",
    "print(f\"{'Pruned':<25} {mse_pruned:<10.4f} {mae_pruned:<10.4f} {r2_pruned:<10.4f}\")\n",
    "print(f\"{'Pruned + Quantized':<25} {mse_quantized:<10.4f} {mae_quantized:<10.4f} {r2_quantized:<10.4f}\")\n",
    "\n",
    "# Cleanup temporary files\n",
    "os.remove(original_model_path)\n",
    "os.remove(temp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions comparison\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "num_samples = min(150, len(y_true_flat))\n",
    "if num_samples > 0:\n",
    "    indices = np.random.choice(len(y_true_flat), num_samples, replace=False)\n",
    "    indices = np.sort(indices)\n",
    "\n",
    "    # Plot 1: Time series comparison\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(indices, y_true_flat[indices], 'b-', label='Actual', alpha=0.7, linewidth=2)\n",
    "    plt.plot(indices, y_pred_flat[indices], 'g--', label='Original', alpha=0.7)\n",
    "    plt.plot(indices, y_pred_pruned.flatten()[indices], 'r--', label='Pruned', alpha=0.7)\n",
    "    plt.plot(indices, y_pred_flat_quant[indices], 'm--', label='Quantized', alpha=0.7)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Sensor Value (Scaled)')\n",
    "    plt.title('Predictions Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 2: Original vs Quantized scatter\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(y_true_flat, y_pred_flat, alpha=0.3, label='Original')\n",
    "    plt.scatter(y_true_flat, y_pred_flat_quant, alpha=0.3, label='Quantized')\n",
    "    mn = min(y_true_flat.min(), y_pred_flat.min(), y_pred_flat_quant.min())\n",
    "    mx = max(y_true_flat.max(), y_pred_flat.max(), y_pred_flat_quant.max())\n",
    "    plt.plot([mn, mx], [mn, mx], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title('Scatter: Original vs Quantized')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot 3: Error distribution\n",
    "    plt.subplot(1, 3, 3)\n",
    "    error_original = np.abs(y_true_flat - y_pred_flat)\n",
    "    error_pruned = np.abs(y_true_flat - y_pred_pruned.flatten())\n",
    "    error_quantized = np.abs(y_true_flat - y_pred_flat_quant)\n",
    "    \n",
    "    plt.hist(error_original, bins=30, alpha=0.5, label='Original', color='green')\n",
    "    plt.hist(error_pruned, bins=30, alpha=0.5, label='Pruned', color='red')\n",
    "    plt.hist(error_quantized, bins=30, alpha=0.5, label='Quantized', color='magenta')\n",
    "    plt.xlabel('Absolute Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Error Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No test samples available to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
