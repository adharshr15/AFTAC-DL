ST Edge AI Core v2.2.0-20266 2adc00962
Created date          : 2025-12-02 01:52:42
Parameters            : generate --target stm32f7 --name soh_model -m C:/Users/redninjale/Downloads/pruned_quantized_model.tflite --compression none --verbosity 1 --workspace C:/Users/REDNIN~1/AppData/Local/Temp/mxAI_workspace4079456299340014326933688587722637 --output C:/Users/redninjale/.stm32cubemx/network_output

Exec/report summary (generate)
---------------------------------------------------------------------------------------------------------------
model file         :   C:\Users\redninjale\Downloads\pruned_quantized_model.tflite                             
type               :   tflite                                                                                  
c_name             :   soh_model                                                                               
compression        :   none                                                                                    
options            :   allocate-inputs, allocate-outputs                                                       
optimization       :   balanced                                                                                
target/series      :   stm32f7                                                                                 
workspace dir      :   C:\Users\REDNIN~1\AppData\Local\Temp\mxAI_workspace4079456299340014326933688587722637   
output dir         :   C:\Users\redninjale\.stm32cubemx\network_output                                         
model_fmt          :   ss/sa per channel                                                                       
model_name         :   pruned_quantized_model                                                                  
model_hash         :   0xabcc673320f81007c2b011713669bca1                                                      
params #           :   70,885 items (69.56 KiB)                                                                
---------------------------------------------------------------------------------------------------------------
input 1/1          :   'serving_default_input_layer_10', f32(1x48x1), 192 Bytes, activations                   
output 1/1         :   'conversion_13', f32(1x1), 4 Bytes, activations                                         
macc               :   87,559                                                                                  
weights (ro)       :   71,232 B (69.56 KiB) (1 segment) / -212,308(-74.9%) vs float model                      
activations (rw)   :   4,776 B (4.66 KiB) (1 segment) *                                                        
ram (total)        :   4,776 B (4.66 KiB) = 4,776 + 0 + 0                                                      
---------------------------------------------------------------------------------------------------------------
(*) 'input'/'output' buffers are allocated in the activations buffer

Model name - pruned_quantized_model
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
m_id   layer (type,original)                      oshape                param/size          macc                     connected to   | c_size          c_macc             c_type              
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
0      serving_default_input_layer_10 (Input, )   [b:1,h:48,c:1]                                                                    |                 +96(+100.0%)       Conversion_[0]      
       conversion_0 (Conversion, QUANTIZE)        [b:1,h:48,c:1]                              96   serving_default_input_layer_10   |                 -96(-100.0%)       
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
1      reshape_1 (Reshape, EXPAND_DIMS)           [b:1,h:1,w:48,c:1]                                                 conversion_0   |                                    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
2      conv2d_2 (Conv2D, CONV_2D)                 [b:1,h:1,w:44,c:64]   384/576           14,144                        reshape_1   |                                    Conv2D_[1]          
       nl_2_nl (Nonlinearity, CONV_2D)            [b:1,h:1,w:44,c:64]                      2,816                         conv2d_2   |                 -2,816(-100.0%)    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
3      reshape_3 (Reshape, RESHAPE)               [b:1,h:44,c:64]                                                         nl_2_nl   |                                    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
4      reshape_4 (Reshape, EXPAND_DIMS)           [b:1,h:1,w:44,c:64]                                                   reshape_3   |                                    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
5      pool_5 (Pool, MAX_POOL_2D)                 [b:1,h:1,w:22,c:64]                      2,816                        reshape_4   |                                    Pool_[2]            
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
6      reshape_6 (Reshape, RESHAPE)               [b:1,h:22,c:64]                                                          pool_5   |                                    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
10     reshape_10 (Reshape, RESHAPE)              [b:1,c:1408]                                                             pool_5   |                                    
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
11     tfl_pseudo_qconst3 (Placeholder, )         [b:50,c:1408]         70,400/70,400                                               | +200(+0.3%)     +70,450(+100.0%)   Dense_[3]           
       tfl_pseudo_qconst2 (Placeholder, )         [b:50]                50/200                                                      | -200(-100.0%)                      
       gemm_11 (Gemm, FULLY_CONNECTED)            [b:1,c:50]                              70,450                       reshape_10   |                 -70,450(-100.0%)   
                                                                                                               tfl_pseudo_qconst3   | 
                                                                                                               tfl_pseudo_qconst2   | 
       nl_11_nl (Nonlinearity, FULLY_CONNECTED)   [b:1,c:50]                                  50                          gemm_11   |                 -50(-100.0%)       
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
12     tfl_pseudo_qconst1 (Placeholder, )         [b:1,c:50]            50/50                                                       | +4(+8.0%)       +51(+100.0%)       Dense_[4]           
       tfl_pseudo_qconst (Placeholder, )          [b:1]                 1/4                                                         | -4(-100.0%)                        
       gemm_12 (Gemm, FULLY_CONNECTED)            [b:1,c:1]                                   51                         nl_11_nl   |                 -51(-100.0%)       
                                                                                                               tfl_pseudo_qconst1   | 
                                                                                                                tfl_pseudo_qconst   | 
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
13     conversion_13 (Conversion, DEQUANTIZE)     [b:1,c:1]                                    2                          gemm_12   |                                    Conversion_[o][5]   
------ ------------------------------------------ --------------------- --------------- -------- -------------------------------- --- --------------- ------------------ ------------------- 
model/c-model: macc=90,425/87,559 -2,866(-3.2%) weights=71,230/71,232 +2(+0.0%) activations=--/4,776 io=--/0



Generated C-graph summary
------------------------------------------------------------------------------------------------------------------------
model name            : pruned_quantized_model
c-name                : soh_model
c-node #              : 6
c-array #             : 16
activations size      : 4776 (1 segment)
weights size          : 71232 (1 segment)
macc                  : 87559
inputs                : ['serving_default_input_layer_10_output']
outputs               : ['conversion_13_output']

C-Arrays (16)
------ --------------------------------------- ------------- ------------------------- ----------- --------- 
c_id   name (*_array)                          item/size     domain/mem-pool           c-type      comment   
------ --------------------------------------- ------------- ------------------------- ----------- --------- 
0      conv2d_2_bias                           64/256        weights/weights           const s32             
1      conv2d_2_output                         2816/2816     activations/**default**   s8                    
2      conv2d_2_scratch0                       1556/1556     activations/**default**   s8                    
3      conv2d_2_weights                        320/320       weights/weights           const s8              
4      conversion_0_output                     48/48         activations/**default**   s8                    
5      conversion_13_output                    1/4           activations/**default**   float       /output   
6      gemm_11_bias                            50/200        weights/weights           const s32             
7      gemm_11_output                          50/50         activations/**default**   s8                    
8      gemm_11_scratch0                        1658/3316     activations/**default**   s16                   
9      gemm_11_weights                         70400/70400   weights/weights           const s8              
10     gemm_12_bias                            1/4           weights/weights           const s32             
11     gemm_12_output                          1/1           activations/**default**   s8                    
12     gemm_12_scratch0                        50/100        activations/**default**   s16                   
13     gemm_12_weights                         50/50         weights/weights           const s8              
14     pool_5_output                           1408/1408     activations/**default**   s8                    
15     serving_default_input_layer_10_output   48/192        activations/**default**   float       /input    
------ --------------------------------------- ------------- ------------------------- ----------- --------- 

C-Layers (6)
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
c_id   name (*_layer)   id   layer_type    macc    rom     tensors                                    shape (array id)       
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
0      conversion_0     0    Conversion    96      0       I: serving_default_input_layer_10_output   f32(1x48x1) (15)       
                                                           O: conversion_0_output                     int8(1x48x1) (4)       
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
1      conv2d_2         2    Conv2D        14144   576     I: conversion_0_output                     int8(1x48x1) (4)       
                                                           S: conv2d_2_scratch0                                              
                                                           W: conv2d_2_weights                        int8(64x1x5x1) (3)     
                                                           W: conv2d_2_bias                           int32(64) (0)          
                                                           O: conv2d_2_output                         int8(1x1x44x64) (1)    
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
2      pool_5           5    Pool          2816    0       I: conv2d_2_output                         int8(1x1x44x64) (1)    
                                                           O: pool_5_output                           int8(1x1x22x64) (14)   
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
3      gemm_11          11   Dense         70450   70600   I: pool_5_output                           int8(1x1x22x64) (14)   
                                                           S: gemm_11_scratch0                                               
                                                           W: gemm_11_weights                         int8(50x1408) (9)      
                                                           W: gemm_11_bias                            int32(50) (6)          
                                                           O: gemm_11_output                          int8(1x50) (7)         
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
4      gemm_12          12   Dense         51      54      I: gemm_11_output                          int8(1x50) (7)         
                                                           S: gemm_12_scratch0                                               
                                                           W: gemm_12_weights                         int8(1x50) (13)        
                                                           W: gemm_12_bias                            int32(1) (10)          
                                                           O: gemm_12_output                          int8(1x1) (11)         
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 
5      conversion_13    13   Conversion    2       0       I: gemm_12_output                          int8(1x1) (11)         
                                                           O: conversion_13_output                    f32(1x1) (5)           
------ ---------------- ---- ------------- ------- ------- ------------------------------------------ ---------------------- 



Number of operations per c-layer
------- ------ ---------------------------- -------- ------------- 
c_id    m_id   name (type)                       #op          type 
------- ------ ---------------------------- -------- ------------- 
0       0      conversion_0 (Conversion)          96   smul_f32_s8 
1       2      conv2d_2 (Conv2D)              14,144    smul_s8_s8 
2       5      pool_5 (Pool)                   2,816    smul_s8_s8 
3       11     gemm_11 (Dense)                70,450    smul_s8_s8 
4       12     gemm_12 (Dense)                    51    smul_s8_s8 
5       13     conversion_13 (Conversion)          2   smul_s8_f32 
------- ------ ---------------------------- -------- ------------- 
total                                         87,559 

Number of operation types
---------------- -------- ----------- 
operation type          #           % 
---------------- -------- ----------- 
smul_f32_s8            96        0.1% 
smul_s8_s8         87,461       99.9% 
smul_s8_f32             2        0.0% 

Complexity report (model)
------ -------------------------------- ------------------------- ------------------------- ------ 
m_id   name                             c_macc                    c_rom                     c_id   
------ -------------------------------- ------------------------- ------------------------- ------ 
0      serving_default_input_layer_10   |                  0.1%   |                  0.0%   [0]    
2      conv2d_2                         ||||              16.2%   |                  0.8%   [1]    
5      pool_5                           |                  3.2%   |                  0.0%   [2]    
11     tfl_pseudo_qconst3               ||||||||||||||||  80.5%   ||||||||||||||||  99.1%   [3]    
12     tfl_pseudo_qconst1               |                  0.1%   |                  0.1%   [4]    
13     conversion_13                    |                  0.0%   |                  0.0%   [5]    
------ -------------------------------- ------------------------- ------------------------- ------ 
macc=87,559 weights=71,232 act=4,776 ram_io=0
 
 Requested memory size by section - "stm32f7" target
 ------------------------------ -------- -------- ------- ------- 
 module                             text   rodata    data     bss 
 ------------------------------ -------- -------- ------- ------- 
 NetworkRuntime1020_CM7_GCC.a     19,284        0       0       0 
 soh_model.o                         592      776   2,176     168 
 soh_model_data.o                     48       16      88       0 
 lib (toolchain)*                  3,580       24       0       0 
 ------------------------------ -------- -------- ------- ------- 
 RT total**                       23,504      816   2,264     168 
 ------------------------------ -------- -------- ------- ------- 
 weights                               0   71,232       0       0 
 activations                           0        0       0   4,776 
 io                                    0        0       0       0 
 ------------------------------ -------- -------- ------- ------- 
 TOTAL                            23,504   72,048   2,264   4,944 
 ------------------------------ -------- -------- ------- ------- 
 *  toolchain objects (libm/libgcc*)
 ** RT AI runtime objects (kernels+infrastructure)
  
  Summary - "stm32f7" target
  ---------------------------------------------------
               FLASH (ro)      %*   RAM (rw)       % 
  ---------------------------------------------------
  RT total         26,584   27.2%      2,432   33.7% 
  ---------------------------------------------------
  TOTAL            97,816              7,208         
  ---------------------------------------------------
  *  rt/total


Generated files (7)
------------------------------------------------------------------------- 
C:\Users\redninjale\.stm32cubemx\network_output\soh_model_data_params.h   
C:\Users\redninjale\.stm32cubemx\network_output\soh_model_data_params.c   
C:\Users\redninjale\.stm32cubemx\network_output\soh_model_data.h          
C:\Users\redninjale\.stm32cubemx\network_output\soh_model_data.c          
C:\Users\redninjale\.stm32cubemx\network_output\soh_model_config.h        
C:\Users\redninjale\.stm32cubemx\network_output\soh_model.h               
C:\Users\redninjale\.stm32cubemx\network_output\soh_model.c               
