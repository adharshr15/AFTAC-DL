{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7a7e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_tcn import TCN\n",
    "from keras import layers, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17eb35",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e069ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.073250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.007613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.634052</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.979169</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.635984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>52.232443</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21597</th>\n",
       "      <td>51.719373</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21598</th>\n",
       "      <td>51.326107</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>52.967035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21600</th>\n",
       "      <td>53.337779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21601 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  label\n",
       "0        50.073250    0.0\n",
       "1        51.007613    0.0\n",
       "2        49.634052    0.0\n",
       "3        46.979169    0.0\n",
       "4        45.635984    0.0\n",
       "...            ...    ...\n",
       "21596    52.232443    0.0\n",
       "21597    51.719373    0.0\n",
       "21598    51.326107    0.0\n",
       "21599    52.967035    0.0\n",
       "21600    53.337779    0.0\n",
       "\n",
       "[21601 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./simulated_dataset/all_data.csv\")\n",
    "\n",
    "df_pivot = df.pivot(index=\"timestamp\", columns=\"sensor_id\", values=[\"temperature\", \"label\"])\n",
    "df_pivot = df_pivot.reset_index(drop=True)\n",
    "\n",
    "df_pivot.head()\n",
    "\n",
    "sensor_dfs = {}\n",
    "\n",
    "for i in range(1, 5):\n",
    "    sensor_df = df_pivot.xs(i, axis=1, level=1).copy()\n",
    "    \n",
    "    # fill temperature NaNs with mean\n",
    "    sensor_df['temperature'] = sensor_df['temperature'].fillna(sensor_df['temperature'].mean())\n",
    "    \n",
    "    # fill label NaNs with mode (most common value)\n",
    "    sensor_df['label'] = sensor_df['label'].fillna(sensor_df['label'].mode()[0])\n",
    "    \n",
    "    sensor_dfs[i] = sensor_df\n",
    "\n",
    "sensor = 2\n",
    "\n",
    "df = sensor_dfs[sensor]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be17b3c",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c1b5c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df['temperature']\n",
    "df['temperature'] = scaler.fit_transform(df[['temperature']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6beb6",
   "metadata": {},
   "source": [
    "Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2c6def12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of past timesteps the TCN sees\n",
    "seq_length = 40\n",
    "\n",
    "# creates sequences based on data with window size == seq_length\n",
    "def create_sequences(df, seq_length=20):\n",
    "    '''\n",
    "    Sequences are needed for giving the model information about history, since feed-forward networks do not know the order of the data.\n",
    "    TCN's expect input of shape [batch_size, num_features, sequence_length]\n",
    "    \n",
    "    Args:\n",
    "        df: time-series data\n",
    "        seq_length: length of each sequence\n",
    "    \n",
    "    Returns:\n",
    "        X (shape: [num_samples, seq_length, num_inputs]), y (shape: [num_samples, num_inputs])\n",
    "    '''\n",
    "    values = df\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - seq_length):\n",
    "        # average of current sequence\n",
    "        X.append(values[i:i + seq_length])\n",
    "        # next value after sequence\n",
    "        y.append(values[i + seq_length])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "weights = np.ones(500) / 500\n",
    "meanDf = np.convolve(df['temperature'], weights, mode='valid')\n",
    "\n",
    "X, y = create_sequences(meanDf, seq_length)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1a27922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21062, 40, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f7940",
   "metadata": {},
   "source": [
    "Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e07e5bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1506],\n",
      "        [0.1504],\n",
      "        [0.1504],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1502],\n",
      "        [0.1500],\n",
      "        [0.1498],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1499],\n",
      "        [0.1501],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1499],\n",
      "        [0.1497],\n",
      "        [0.1500],\n",
      "        [0.1502],\n",
      "        [0.1502],\n",
      "        [0.1501],\n",
      "        [0.1501],\n",
      "        [0.1501],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1501],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1502],\n",
      "        [0.1502],\n",
      "        [0.1500],\n",
      "        [0.1498],\n",
      "        [0.1497],\n",
      "        [0.1497],\n",
      "        [0.1500],\n",
      "        [0.1501],\n",
      "        [0.1499],\n",
      "        [0.1499]])\n",
      "tensor([0.1500])\n",
      "tensor([[0.1504],\n",
      "        [0.1504],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1502],\n",
      "        [0.1500],\n",
      "        [0.1498],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1499],\n",
      "        [0.1501],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1499],\n",
      "        [0.1497],\n",
      "        [0.1500],\n",
      "        [0.1502],\n",
      "        [0.1502],\n",
      "        [0.1501],\n",
      "        [0.1501],\n",
      "        [0.1501],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1501],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1502],\n",
      "        [0.1502],\n",
      "        [0.1500],\n",
      "        [0.1498],\n",
      "        [0.1497],\n",
      "        [0.1497],\n",
      "        [0.1500],\n",
      "        [0.1501],\n",
      "        [0.1499],\n",
      "        [0.1499],\n",
      "        [0.1500]])\n",
      "tensor([0.1501])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = int(.8 * len(X))\n",
    "val_size = int(.1 * len(X))\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722648d",
   "metadata": {},
   "source": [
    "DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1cab7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "# test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b4950",
   "metadata": {},
   "source": [
    "Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4ae53167",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 1\n",
    "num_channels = [16, 32, 16]\n",
    "kernel_size = 4\n",
    "dilations = [1, 2, 4]\n",
    "dropout = 0.1\n",
    "\n",
    "model = TCN(\n",
    "    num_inputs=num_inputs,\n",
    "    num_channels=num_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    dilations=dilations,\n",
    "    dropout=dropout,\n",
    "    causal=True,\n",
    "    use_skip_connections=True,\n",
    "    output_projection=1,\n",
    "    output_activation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e779c",
   "metadata": {},
   "source": [
    "Loss and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "48eb87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e75b1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 1])\n",
      "tensor([0.1792, 0.1789, 0.1789, 0.1789, 0.1787, 0.1787, 0.1789, 0.1790, 0.1791,\n",
      "        0.1790, 0.1793, 0.1791, 0.1790, 0.1790, 0.1789, 0.1790, 0.1789, 0.1790,\n",
      "        0.1789, 0.1791, 0.1793, 0.1795, 0.1794, 0.1795, 0.1794, 0.1793, 0.1793,\n",
      "        0.1793, 0.1792, 0.1789, 0.1790, 0.1793, 0.1791, 0.1791, 0.1793, 0.1794,\n",
      "        0.1796, 0.1795, 0.1794, 0.1792])\n",
      "tensor(0.1791)\n",
      "tensor([[0.1793],\n",
      "        [0.2236],\n",
      "        [0.1999],\n",
      "        [0.1719],\n",
      "        [0.2439],\n",
      "        [0.2008],\n",
      "        [0.1944],\n",
      "        [0.1977],\n",
      "        [0.4024],\n",
      "        [0.2378],\n",
      "        [0.2308],\n",
      "        [0.2025],\n",
      "        [0.2444],\n",
      "        [0.4042],\n",
      "        [0.2250],\n",
      "        [0.3590],\n",
      "        [0.1537],\n",
      "        [0.2298],\n",
      "        [0.2121],\n",
      "        [0.2060],\n",
      "        [0.2059],\n",
      "        [0.2379],\n",
      "        [0.2114],\n",
      "        [0.1726],\n",
      "        [0.1735],\n",
      "        [0.1777],\n",
      "        [0.2067],\n",
      "        [0.1747],\n",
      "        [0.1530],\n",
      "        [0.1761],\n",
      "        [0.2492],\n",
      "        [0.1870]])\n",
      "tensor([[0.2232, 0.2230, 0.2229, 0.2231, 0.2229, 0.2230, 0.2232, 0.2231, 0.2231,\n",
      "         0.2229, 0.2230, 0.2229, 0.2228, 0.2228, 0.2229, 0.2229, 0.2231, 0.2231,\n",
      "         0.2232, 0.2232, 0.2232, 0.2233, 0.2231, 0.2228, 0.2227, 0.2229, 0.2232,\n",
      "         0.2230, 0.2232, 0.2233, 0.2233, 0.2234, 0.2234, 0.2233, 0.2233, 0.2230,\n",
      "         0.2230, 0.2233, 0.2234, 0.2236]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_loader:\n",
    "    print(x_batch.shape)  # [B, seq_len, 1]\n",
    "    x_batch = x_batch.permute(0, 2, 1)\n",
    "    print(x_batch[0][0])\n",
    "    print(torch.mean(x_batch[0][0]))\n",
    "    print(y_batch)\n",
    "    print(x_batch[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0814e",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "47549c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train Loss: 0.5100, Validation Loss: 0.5713\n",
      "Epoch 2/30 - Train Loss: 0.5054, Validation Loss: 0.5713\n",
      "Epoch 3/30 - Train Loss: 0.5052, Validation Loss: 0.5713\n",
      "Epoch 4/30 - Train Loss: 0.5051, Validation Loss: 0.5713\n",
      "Epoch 5/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 6/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 7/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 8/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 9/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 10/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 11/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 12/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 13/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 14/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 15/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 16/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 17/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 18/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 19/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 20/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 21/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 22/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 23/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 24/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 25/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 26/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 27/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 28/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 29/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n",
      "Epoch 30/30 - Train Loss: 0.5050, Validation Loss: 0.5713\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # train\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # reorders tensors to [batch_size, features, sequence_length] and ensures y is a float\n",
    "        x_batch = x_batch.permute(0, 2, 1)\n",
    "        \n",
    "        # clears gradients from previous batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward propagation\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(y_pred[:, :, -1], y_batch)\n",
    "        \n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update step and accumulate loss\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x_batch.size(0)\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.permute(0, 2, 1)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred[:, :, -1], y_batch)\n",
    "            val_loss += loss.item() * x_batch.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "            \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b4291ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 1.595295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprau\\AppData\\Local\\Temp\\ipykernel_28556\\1384576375.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
      "C:\\Users\\aprau\\AppData\\Local\\Temp\\ipykernel_28556\\1384576375.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_t = torch.tensor(y_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t) \n",
    "    \n",
    "criterion = torch.nn.MSELoss()  \n",
    "test_loss = criterion(y_pred[:, :, -1], y_test_t).item()\n",
    "\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
