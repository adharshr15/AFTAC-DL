{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "d7a7e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pytorch_tcn import TCN\n",
    "from keras import layers, models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17eb35",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e069ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.441279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.375508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.001814</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.346798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.003479</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21710</th>\n",
       "      <td>47.484230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21711</th>\n",
       "      <td>47.484230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>47.484230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21713</th>\n",
       "      <td>47.484230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21714</th>\n",
       "      <td>47.484230</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21715 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature  label\n",
       "0        49.441279    0.0\n",
       "1        50.375508    0.0\n",
       "2        49.001814    0.0\n",
       "3        46.346798    0.0\n",
       "4        45.003479    0.0\n",
       "...            ...    ...\n",
       "21710    47.484230    0.0\n",
       "21711    47.484230    0.0\n",
       "21712    47.484230    0.0\n",
       "21713    47.484230    0.0\n",
       "21714    47.484230    0.0\n",
       "\n",
       "[21715 rows x 2 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./simulated_dataset/all_data.csv\")\n",
    "\n",
    "df_pivot = df.pivot(index=\"timestamp\", columns=\"sensor_id\", values=[\"temperature\", \"label\"])\n",
    "df_pivot = df_pivot.reset_index(drop=True)\n",
    "\n",
    "df_pivot.head()\n",
    "\n",
    "sensor_dfs = {}\n",
    "\n",
    "for i in range(1, 5):\n",
    "    sensor_df = df_pivot.xs(i, axis=1, level=1).copy()\n",
    "    \n",
    "    # fill temperature NaNs with mean\n",
    "    sensor_df['temperature'] = sensor_df['temperature'].fillna(sensor_df['temperature'].mean())\n",
    "    \n",
    "    # fill label NaNs with mode (most common value)\n",
    "    sensor_df['label'] = sensor_df['label'].fillna(sensor_df['label'].mode()[0])\n",
    "    \n",
    "    sensor_dfs[i] = sensor_df\n",
    "\n",
    "sensor = 2\n",
    "\n",
    "df = sensor_dfs[sensor]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be17b3c",
   "metadata": {},
   "source": [
    "Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "c1b5c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df['temperature']\n",
    "df['temperature'] = scaler.fit_transform(df[['temperature']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6beb6",
   "metadata": {},
   "source": [
    "Create Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "2c6def12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of past timesteps the TCN sees\n",
    "seq_length = 40\n",
    "\n",
    "# creates sequences based on data with window size == seq_length\n",
    "def create_sequences(df, seq_length=20):\n",
    "    '''\n",
    "    Sequences are needed for giving the model information about history, since feed-forward networks do not know the order of the data.\n",
    "    TCN's expect input of shape [batch_size, num_features, sequence_length]\n",
    "    \n",
    "    Args:\n",
    "        df: time-series data\n",
    "        seq_length: length of each sequence\n",
    "    \n",
    "    Returns:\n",
    "        X (shape: [num_samples, seq_length, num_inputs]), y (shape: [num_samples, num_inputs])\n",
    "    '''\n",
    "    values = df['temperature'].values\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - seq_length):\n",
    "        # sequence\n",
    "        X.append(values[i:i + seq_length])\n",
    "        # next value after sequence\n",
    "        y.append(values[i + seq_length])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = create_sequences(df, seq_length)\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)\n",
    "y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f7940",
   "metadata": {},
   "source": [
    "Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "e07e5bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1928],\n",
      "        [0.2113],\n",
      "        [0.1842],\n",
      "        [0.1319],\n",
      "        [0.1054],\n",
      "        [0.0113],\n",
      "        [0.1785],\n",
      "        [0.1741],\n",
      "        [0.0960],\n",
      "        [0.1256],\n",
      "        [0.1844],\n",
      "        [0.0447],\n",
      "        [0.1466],\n",
      "        [0.1114],\n",
      "        [0.1803],\n",
      "        [0.1325],\n",
      "        [0.0628],\n",
      "        [0.0182],\n",
      "        [0.1438],\n",
      "        [0.0940],\n",
      "        [0.1801],\n",
      "        [0.1757],\n",
      "        [0.1332],\n",
      "        [0.1814],\n",
      "        [0.1483],\n",
      "        [0.1685],\n",
      "        [0.1287],\n",
      "        [0.1439],\n",
      "        [0.1989],\n",
      "        [0.0304],\n",
      "        [0.1222],\n",
      "        [0.1116],\n",
      "        [0.1839],\n",
      "        [0.1111],\n",
      "        [0.0675],\n",
      "        [0.0250],\n",
      "        [0.0709],\n",
      "        [0.1665],\n",
      "        [0.1777],\n",
      "        [0.1044]])\n",
      "tensor([0.0253])\n",
      "tensor([[0.2113],\n",
      "        [0.1842],\n",
      "        [0.1319],\n",
      "        [0.1054],\n",
      "        [0.0113],\n",
      "        [0.1785],\n",
      "        [0.1741],\n",
      "        [0.0960],\n",
      "        [0.1256],\n",
      "        [0.1844],\n",
      "        [0.0447],\n",
      "        [0.1466],\n",
      "        [0.1114],\n",
      "        [0.1803],\n",
      "        [0.1325],\n",
      "        [0.0628],\n",
      "        [0.0182],\n",
      "        [0.1438],\n",
      "        [0.0940],\n",
      "        [0.1801],\n",
      "        [0.1757],\n",
      "        [0.1332],\n",
      "        [0.1814],\n",
      "        [0.1483],\n",
      "        [0.1685],\n",
      "        [0.1287],\n",
      "        [0.1439],\n",
      "        [0.1989],\n",
      "        [0.0304],\n",
      "        [0.1222],\n",
      "        [0.1116],\n",
      "        [0.1839],\n",
      "        [0.1111],\n",
      "        [0.0675],\n",
      "        [0.0250],\n",
      "        [0.0709],\n",
      "        [0.1665],\n",
      "        [0.1777],\n",
      "        [0.1044],\n",
      "        [0.0253]])\n",
      "tensor([0.0402])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_size = int(.8 * len(X))\n",
    "val_size = int(.1 * len(X))\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]\n",
    "X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722648d",
   "metadata": {},
   "source": [
    "DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "1cab7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "# test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b4950",
   "metadata": {},
   "source": [
    "Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "4ae53167",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 1\n",
    "num_channels = [16, 32, 16]\n",
    "kernel_size = 4\n",
    "dilations = [1, 2, 4]\n",
    "dropout = 0.1\n",
    "\n",
    "model = TCN(\n",
    "    num_inputs=num_inputs,\n",
    "    num_channels=num_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    dilations=dilations,\n",
    "    dropout=dropout,\n",
    "    causal=True,\n",
    "    use_skip_connections=True,\n",
    "    output_projection=1,\n",
    "    output_activation=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e779c",
   "metadata": {},
   "source": [
    "Loss and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "48eb87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "e75b1f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40, 1])\n",
      "tensor([[[0.0682, 0.1900, 0.0430,  ..., 0.0669, 0.0941, 0.2288]],\n",
      "\n",
      "        [[0.0776, 0.1597, 0.2159,  ..., 0.0633, 0.1646, 0.2042]],\n",
      "\n",
      "        [[0.1927, 0.1695, 0.0932,  ..., 0.2236, 0.0985, 0.1207]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2032, 0.1307, 0.0300,  ..., 0.0388, 0.0751, 0.1329]],\n",
      "\n",
      "        [[0.0638, 0.1729, 0.0701,  ..., 0.1294, 0.1876, 0.1976]],\n",
      "\n",
      "        [[0.0735, 0.1586, 0.0563,  ..., 0.2204, 0.2381, 0.2557]]])\n",
      "tensor([[0.1938],\n",
      "        [0.2125],\n",
      "        [0.1010],\n",
      "        [0.0509],\n",
      "        [0.0818],\n",
      "        [0.1434],\n",
      "        [0.0784],\n",
      "        [0.0805],\n",
      "        [0.0916],\n",
      "        [0.0745],\n",
      "        [0.1399],\n",
      "        [0.2099],\n",
      "        [0.2192],\n",
      "        [0.1253],\n",
      "        [0.1266],\n",
      "        [0.1689],\n",
      "        [0.1878],\n",
      "        [0.1786],\n",
      "        [0.0652],\n",
      "        [0.1409],\n",
      "        [0.0781],\n",
      "        [0.0359],\n",
      "        [0.1532],\n",
      "        [0.6891],\n",
      "        [0.1872],\n",
      "        [0.0664],\n",
      "        [0.1218],\n",
      "        [0.0720],\n",
      "        [0.1195],\n",
      "        [0.1696],\n",
      "        [0.2041],\n",
      "        [0.1059]])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, y_batch in train_loader:\n",
    "    print(x_batch.shape)  # [B, seq_len, 1]\n",
    "    x_batch = x_batch.permute(0, 2, 1)\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0814e",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "47549c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train Loss: 0.4097, Validation Loss: 0.4963\n",
      "Epoch 2/30 - Train Loss: 0.4014, Validation Loss: 0.4979\n",
      "Epoch 3/30 - Train Loss: 0.4009, Validation Loss: 0.4959\n",
      "Epoch 4/30 - Train Loss: 0.4006, Validation Loss: 0.4958\n",
      "Epoch 5/30 - Train Loss: 0.4003, Validation Loss: 0.4967\n",
      "Epoch 6/30 - Train Loss: 0.4003, Validation Loss: 0.4963\n",
      "Epoch 7/30 - Train Loss: 0.4001, Validation Loss: 0.4964\n",
      "Epoch 8/30 - Train Loss: 0.4001, Validation Loss: 0.4963\n",
      "Epoch 9/30 - Train Loss: 0.4001, Validation Loss: 0.4967\n",
      "Epoch 10/30 - Train Loss: 0.4000, Validation Loss: 0.4960\n",
      "Epoch 11/30 - Train Loss: 0.4000, Validation Loss: 0.4973\n",
      "Epoch 12/30 - Train Loss: 0.4000, Validation Loss: 0.4962\n",
      "Epoch 13/30 - Train Loss: 0.4001, Validation Loss: 0.4972\n",
      "Epoch 14/30 - Train Loss: 0.4000, Validation Loss: 0.4960\n",
      "Epoch 15/30 - Train Loss: 0.4000, Validation Loss: 0.4980\n",
      "Epoch 16/30 - Train Loss: 0.4000, Validation Loss: 0.4960\n",
      "Epoch 17/30 - Train Loss: 0.4000, Validation Loss: 0.4975\n",
      "Epoch 18/30 - Train Loss: 0.4000, Validation Loss: 0.4975\n",
      "Epoch 19/30 - Train Loss: 0.4000, Validation Loss: 0.4964\n",
      "Epoch 20/30 - Train Loss: 0.4000, Validation Loss: 0.4960\n",
      "Epoch 21/30 - Train Loss: 0.4000, Validation Loss: 0.4958\n",
      "Epoch 22/30 - Train Loss: 0.3999, Validation Loss: 0.4959\n",
      "Epoch 23/30 - Train Loss: 0.4000, Validation Loss: 0.4961\n",
      "Epoch 24/30 - Train Loss: 0.3999, Validation Loss: 0.4959\n",
      "Epoch 25/30 - Train Loss: 0.3999, Validation Loss: 0.4960\n",
      "Epoch 26/30 - Train Loss: 0.4000, Validation Loss: 0.4966\n",
      "Epoch 27/30 - Train Loss: 0.3999, Validation Loss: 0.4967\n",
      "Epoch 28/30 - Train Loss: 0.4000, Validation Loss: 0.4979\n",
      "Epoch 29/30 - Train Loss: 0.4000, Validation Loss: 0.4963\n",
      "Epoch 30/30 - Train Loss: 0.3999, Validation Loss: 0.4960\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # train\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # reorders tensors to [batch_size, features, sequence_length] and ensures y is a float\n",
    "        x_batch = x_batch.permute(0, 2, 1)\n",
    "        # clears gradients from previous batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward propagation\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        # y_pred = model(x_batch)\n",
    "        loss = criterion(y_pred[:, :, -1], y_batch)\n",
    "        \n",
    "        # backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update step and accumulate loss\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x_batch.size(0)\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.permute(0, 2, 1)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred[:, :, -1], y_batch)\n",
    "            val_loss += loss.item() * x_batch.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "            \n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "b4291ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss (MSE): 2.913255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aprau\\AppData\\Local\\Temp\\ipykernel_16204\\1384576375.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
      "C:\\Users\\aprau\\AppData\\Local\\Temp\\ipykernel_16204\\1384576375.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test_t = torch.tensor(y_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t) \n",
    "    \n",
    "criterion = torch.nn.MSELoss()  \n",
    "test_loss = criterion(y_pred[:, :, -1], y_test_t).item()\n",
    "\n",
    "print(f\"Test Loss (MSE): {test_loss:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
